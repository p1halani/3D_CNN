{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from random import randint\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import fbeta_score, precision_recall_fscore_support, multilabel_confusion_matrix\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import csv\n",
    "def read_dict(path):\n",
    "    'Reads Python dictionary stored in a csv file'\n",
    "    dictionary = {}\n",
    "    for key, val in csv.reader(open(path)):\n",
    "        dictionary[key] = val\n",
    "    return dictionary\n",
    "\n",
    "torch.set_num_threads(5)\n",
    "\n",
    "scaling_weights = True\n",
    "p = 0\n",
    "v_size = 32\n",
    "flips = (0.2, 0.2, 0.2)\n",
    "max_radius = 40\n",
    "shuffle = False\n",
    "noise_treatment = False\n",
    "period_checkpoint = 50\n",
    "# current_file_name = os.path.basename(__file__)[:-3]\n",
    "PERCENTILE = 99.7\n",
    "DISABLE_TQDM = True\n",
    "precomputed_path = '../files/precomputed/'\n",
    "PDB_path = '../files/PDB/'\n",
    "train_dir = '../pictures/train/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"-----------------------Parameters Change--------------------------------\"\"\"\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 0.00007\n",
    "output_dim = 0\n",
    "# 'hydropathy', 'charge', 'isoelectric'\n",
    "weights = []\n",
    "batch_size = 50\n",
    "max_epochs = 20\n",
    "type_of_dataset = '1'\n",
    "\n",
    "\"\"\"-----------------------Parameters Changed-------------------------------\"\"\"\n",
    "\n",
    "if type_of_dataset == '1':\n",
    "    output_dim = 932\n",
    "    d = 'bp'\n",
    "if type_of_dataset == '2':\n",
    "    output_dim = 439\n",
    "    d = 'cc'\n",
    "if type_of_dataset == '3':\n",
    "    output_dim = 589\n",
    "    d = 'mf'\n",
    "\n",
    "if len(weights) == 0:\n",
    "    input_channels = 1\n",
    "    name = 'None'\n",
    "else:\n",
    "    input_channels = 3\n",
    "    name = 'hci'\n",
    "    \n",
    "features_save = 'best_features/3d/features_{}_{}.pkl'.format(d, name)\n",
    "labels_csv = '../labels/struct/new_{}.csv'.format(type_of_dataset)\n",
    "weights_path = 'Weights/3d/weights_3d_{}_{}.pth'.format(d, name)\n",
    "input_shape = (input_channels, 32, 32, 32)\n",
    "num_features = input_channels * 256\n",
    "print(device)\n",
    "n_channels = 1 + len(weights)\n",
    "stddev_conv3d = np.sqrt(2.0/(n_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation_Data Length: 2598\n",
      "Train_Data Length: 8500\n",
      "Label type: <class 'numpy.ndarray'>\tEach Label type: <class 'numpy.int64'>\n",
      "Example of accession_no: A0A0H2VDN9\n"
     ]
    }
   ],
   "source": [
    "acc_pdb = read_dict('../datasets/new_dataset_pdb_{}.csv'.format(type_of_dataset))\n",
    "\n",
    "df = pd.read_csv('../datasets/new_{}.csv'.format(type_of_dataset))\n",
    "acc_labels = []\n",
    "for idx,row in df.iterrows():\n",
    "    temp = list(int(i) for i in row[1].strip().split(','))\n",
    "    acc_labels.append([row[0],np.array(temp)])\n",
    "    \n",
    "# acc_labels = np.array(acc_labels)\n",
    "    \n",
    "train_acc_labels = acc_labels[:8500]\n",
    "val_acc_labels = acc_labels[8500:]\n",
    "train_df = pd.DataFrame(train_acc_labels)\n",
    "val_df = pd.DataFrame(val_acc_labels)\n",
    "print(f\"Validation_Data Length: {len(val_df)}\\nTrain_Data Length: {len(train_df)}\")\n",
    "print(f\"Label type: {type(train_df.iloc[0,1])}\\tEach Label type: {type(train_df.iloc[0,1][0])}\")\n",
    "print(f\"Example of accession_no: {train_df.iloc[0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "class VolumeData(data.Dataset):\n",
    "    def __init__(self,df,dirpath,transform,test = False):\n",
    "        \n",
    "        self.df = df\n",
    "        self.directory_precomputed = precomputed_path\n",
    "        self.directory_pdb = PDB_path\n",
    "        self.flips = flips\n",
    "        self.acc_labels = df.values.tolist()\n",
    "        self.acc_pdb = acc_pdb\n",
    "        self.max_radius = max_radius\n",
    "        self.noise_treatment = noise_treatment\n",
    "        self.n_channels = max(1, len(weights))\n",
    "        self.p = p\n",
    "        self.scaling_weights = scaling_weights\n",
    "        self.shuffle = shuffle\n",
    "        self.v_size = v_size\n",
    "        self.weights = weights\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "#         acc = list(self.acc_pdb)\n",
    "#         pdb_id = self.acc_pdb[acc[idx]]\n",
    "        X, y = self.__data_augmentation(idx)\n",
    "        \n",
    "        label_tensor = torch.zeros((1, output_dim))\n",
    "        z = torch.from_numpy(y)\n",
    "        for j,ele in enumerate(z):\n",
    "            label_tensor[0, j] = ele\n",
    "        image_label = torch.tensor(label_tensor,dtype= torch.float32)\n",
    "        \n",
    "        #   convert X to tensor\n",
    "        \n",
    "        return (X, image_label.squeeze())\n",
    "    \n",
    "    def __data_augmentation(self, idx):\n",
    "        'Returns augmented data with batch_size enzymes' # X : (v_size, v_size, v_size, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.n_channels,\n",
    "                      self.v_size,\n",
    "                      self.v_size,\n",
    "                      self.v_size))\n",
    "        try:\n",
    "                   \n",
    "            y = np.empty(len(self.acc_labels[idx][1]), dtype=int)\n",
    "\n",
    "            # Computations\n",
    "            if len(self.acc_labels[idx]) != 2:\n",
    "                print(len(self.labels[idx]), end = ' ')\n",
    "            y = self.acc_labels[idx][1]\n",
    "            pdb_id = self.acc_pdb[self.acc_labels[idx][0]]\n",
    "\n",
    "            # Load precomputed coordinates\n",
    "            coords = load_coords(pdb_id, self.p, self.directory_precomputed)\n",
    "            coords = coords_center_to_zero(coords)\n",
    "            coords = adjust_size(coords, v_size=self.v_size, max_radius=self.max_radius)\n",
    "\n",
    "            # Get weights\n",
    "            local_weights = []\n",
    "            for weight in self.weights:\n",
    "                local_weight = load_weights(pdb_id, weight, self.p,\n",
    "                                            self.scaling_weights, self.directory_precomputed) # Compute extended weights\n",
    "                local_weights += [local_weight] # Store\n",
    "                \n",
    "\n",
    "            # PCA\n",
    "            coords = PCA(n_components=3).fit_transform(coords)\n",
    "\n",
    "            # Do flip\n",
    "            coords_temp = flip_around_axis(coords, axis=self.flips)\n",
    "\n",
    "            if len(self.weights) == 0:\n",
    "                # Convert to volume and store\n",
    "                X[0, :, :, :] = coords_to_volume(coords_temp, self.v_size,\n",
    "                                                    noise_treatment=self.noise_treatment)\n",
    "\n",
    "            else:\n",
    "                # Compute to weights of volume and store\n",
    "                for k in range(self.n_channels):\n",
    "                    X[k, :, :, :] = weights_to_volume(coords_temp, local_weights[k],\n",
    "                                                         self.v_size, noise_treatment=self.noise_treatment)\n",
    "\n",
    "            return X, np.array(y)\n",
    "        except:\n",
    "            print(idx)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.acc_pdb))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "def load_coords(pdb_id, desired_p, source_path):\n",
    "    'Loads precomputed coordinates'\n",
    "    return np.load(precomputed_name(pdb_id, source_path, 'coords', desired_p))\n",
    "    \n",
    "def coords_center_to_zero(coords):\n",
    "    'Centering coordinates on [0,0,0]'\n",
    "    barycenter = get_barycenter(coords)\n",
    "    return coords - np.full((coords.shape[0], 3), barycenter)\n",
    "\n",
    "def adjust_size(coords, v_size=32, max_radius=40):\n",
    "    return np.multiply((v_size/2-1)/max_radius, coords)\n",
    "\n",
    "def load_weights(pdb_id, weights_name, desired_p, scaling, source_path):\n",
    "    'Loads precomputed weights'\n",
    "    return np.load(precomputed_name(pdb_id, source_path, 'weights', desired_p, weights_name, scaling))\n",
    "\n",
    "def flip_around_axis(coords, axis=(0.2, 0.2, 0.2)):\n",
    "    'Flips coordinates randomly w.r.t. each axis with its associated probability'\n",
    "    for col in range(3):\n",
    "        if np.random.binomial(1, axis[col]):\n",
    "            coords[:,col] = np.negative(coords[:,col])\n",
    "    return coords\n",
    "\n",
    "def coords_to_volume(coords, v_size, noise_treatment=False):\n",
    "    'Converts coordinates to binary voxels' # Input is centered on [0,0,0]\n",
    "    return weights_to_volume(coords=coords, weights=1, v_size=v_size, noise_treatment=noise_treatment)\n",
    "\n",
    "def weights_to_volume(coords, weights, v_size, noise_treatment=False):\n",
    "    'Converts coordinates to voxels with weights' # Input is centered on [0,0,0]\n",
    "    # Initialization\n",
    "    volume = np.zeros((v_size, v_size, v_size))\n",
    "\n",
    "    # Translate center\n",
    "    coords = coords + np.full((coords.shape[0], 3), (v_size-1)/2)\n",
    "\n",
    "    # Round components\n",
    "    coords = coords.astype(int)\n",
    "\n",
    "    # Filter rows with values that are out of the grid\n",
    "    mask = ((coords >= 0) & (coords < v_size)).all(axis=1)\n",
    "\n",
    "    # Convert to volume\n",
    "    volume[tuple(coords[mask].T)] = weights[mask] if type(weights) != int else weights\n",
    "\n",
    "    # Remove noise\n",
    "    if noise_treatment == True:\n",
    "        volume = remove_noise(coords, volume)\n",
    "\n",
    "    return volume\n",
    "\n",
    "def precomputed_name(pdb_id, path, type_file, desired_p, weights_name=None, scaling=True):\n",
    "    'Returns path in string of precomputed file'\n",
    "    if type_file == 'coords':\n",
    "        return os.path.join(path, pdb_id.lower() + '_coords_p' + str(desired_p) + '.npy')\n",
    "    elif type_file == 'weights':\n",
    "        return os.path.join(path, pdb_id.lower() + '_' + weights_name + '_p' + str(desired_p) + '_scaling' + str(scaling) + '.npy')\n",
    "    \n",
    "def get_barycenter(coords):\n",
    "    'Gets barycenter point of a Nx3 matrix'\n",
    "    return np.array([np.mean(coords, axis=0)])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "train_dataset = VolumeData(train_df,train_dir,data_transforms)\n",
    "train_loader = data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = VolumeData(val_df,train_dir,data_transforms)\n",
    "val_loader = data.DataLoader(dataset=val_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "dataloaders_dict = {'train':train_loader, 'val':val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features: torch.Size([50, 1, 32, 32, 32])\n",
      "Train Labels: torch.Size([50, 932])\n",
      "\n",
      "Validation Features: torch.Size([50, 1, 32, 32, 32])\n",
      "Validation Labels: torch.Size([50, 932])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_loader))\n",
    "print(f'Train Features: {features.shape}\\nTrain Labels: {labels.shape}')\n",
    "print()\n",
    "features, labels = next(iter(val_loader))\n",
    "print(f'Validation Features: {features.shape}\\nValidation Labels: {labels.shape}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "training examples:  8500\n",
      "batch size:  50\n",
      "batches available:  170\n",
      "\n",
      "VALIDATION\n",
      "validation examples:  2598\n",
      "batch size:  50\n",
      "batches available:  52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING\")\n",
    "print(\"training examples: \",len(train_dataset))\n",
    "print(\"batch size: \",batch_size)\n",
    "print(\"batches available: \",len(train_loader))\n",
    "print()\n",
    "print(\"VALIDATION\")\n",
    "print(\"validation examples: \",len(val_dataset))\n",
    "print(\"batch size: \",batch_size)\n",
    "print(\"batches available: \",len(val_loader))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE NETWORK\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "\n",
    "class _3d_cnn(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        \"\"\"\n",
    "        :param input_shape: input image shape, (h, w, c)\n",
    "        \"\"\"\n",
    "        super(_3d_cnn, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(input_channels,  16, (5, 1, 3), stride=(1, 1, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(16, 16, (1, 9, 3), stride=(1, 2, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool3d((2, 1, 1), stride=(2, 1, 1)),\n",
    "\n",
    "            nn.Conv3d(16, 32, kernel_size=(4, 1, 3), stride=(1, 1, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(32, 32, kernel_size=(1, 8, 3), stride=(1, 2, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool3d((2, 1, 1), stride=(2, 1, 1)),\n",
    "            \n",
    "            nn.AvgPool3d(2)\n",
    "        )\n",
    "\n",
    "        # Compute number of input features for the last fully-connected layer\n",
    "        input_shape = (1,) + input_shape\n",
    "        x = Variable(torch.rand(input_shape), requires_grad=False)\n",
    "        x = self.features(x)\n",
    "        x = Flatten()(x)\n",
    "        self.n = x.size()[1]\n",
    "        \n",
    "        print(num_features)\n",
    "        self.fc1 = nn.Linear(self.n, num_features)\n",
    "        self.fc2 = nn.Linear(num_features, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(self.n)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = Flatten()(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.bn2(F.relu(self.fc1(x)))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "class AvgPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.avg_pool3d(x, x.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5119, 0.4894, 0.5012,  ..., 0.5068, 0.5109, 0.5142],\n",
       "        [0.5119, 0.4894, 0.5012,  ..., 0.5068, 0.5109, 0.5142],\n",
       "        [0.5119, 0.4894, 0.5012,  ..., 0.5068, 0.5109, 0.5142],\n",
       "        [0.5119, 0.4894, 0.5012,  ..., 0.5068, 0.5109, 0.5142]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = _3d_cnn(input_shape, output_dim)\n",
    "\n",
    "temp(torch.zeros(4,input_channels,32,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_3d_cnn(\n",
       "  (features): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(5, 1, 3), stride=(1, 1, 1))\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Conv3d(16, 16, kernel_size=(1, 9, 3), stride=(1, 2, 1))\n",
       "    (3): PReLU(num_parameters=1)\n",
       "    (4): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv3d(16, 32, kernel_size=(4, 1, 3), stride=(1, 1, 1))\n",
       "    (6): PReLU(num_parameters=1)\n",
       "    (7): Conv3d(32, 32, kernel_size=(1, 8, 3), stride=(1, 2, 1))\n",
       "    (8): PReLU(num_parameters=1)\n",
       "    (9): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=932, bias=True)\n",
       "  (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNet = _3d_cnn(input_shape, output_dim)\n",
    "NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476,408 total parameters.\n",
      "476,408 training parameters.\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in NeuralNet.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(p.numel() for p in NeuralNet.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuralNet = NeuralNet.to(device)\n",
    "optimizer = optim.Adam(NeuralNet.parameters(),lr = lr)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience = 2)\n",
    "best_loss = np.inf\n",
    "best_f_score = np.inf\n",
    "best_precision = np.inf\n",
    "best_recall = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = []\n",
    "recall = []\n",
    "f = []\n",
    "losss = []\n",
    "val_f = []\n",
    "val_loss = []\n",
    "val_prec = []\n",
    "val_recall = []\n",
    "\n",
    "def store(phase,p,r,fs,l):\n",
    "    if phase == 'train':\n",
    "        prec.append(p)\n",
    "        recall.append(r)\n",
    "        f.append(fs)\n",
    "        losss.append(l)\n",
    "    else:\n",
    "        val_prec.append(p)\n",
    "        val_recall.append(r)\n",
    "        val_f.append(fs)\n",
    "        val_loss.append(l)\n",
    "        \n",
    "def calc(l,f,p,r,length):\n",
    "    loss = l/length\n",
    "    pre = p/length\n",
    "    fs = f/length\n",
    "    re = r/length\n",
    "    \n",
    "    return loss,fs,pre,re\n",
    "\n",
    "def result(epoch, NUM_EPOCHS,phase,epoch_loss,epoch_f_loss,epoch_precision,epoch_recall,elapsed_time):\n",
    "    print(\"\\tPhase: {}\\n\\t\\t Epoch: {}/{} | {}_loss:{:.8f} | f_score:{:.8f} | precision:{:.8f} | recall:{:.8f} | Time: {:.4f}s\".format(phase,\n",
    "                                                                              epoch+1,\n",
    "                                                                              NUM_EPOCHS,\n",
    "                                                                              phase,\n",
    "                                                                              epoch_loss,\n",
    "                                                                              epoch_f_score,\n",
    "                                                                              epoch_precision,\n",
    "                                                                              epoch_recall,\n",
    "                                                                              elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tPhase: train\n",
      "\t\t Epoch: 1/20 | train_loss:0.95076383 | f_score:0.05269638 | precision:0.04299893 | recall:0.99987604 | Time: 173.0518s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 1/20 | val_loss:0.94571218 | f_score:0.04712442 | precision:0.03833212 | recall:0.99972771 | Time: 52.9640s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 2/20 | train_loss:0.93145226 | f_score:0.05267794 | precision:0.04298398 | recall:0.99936603 | Time: 177.3520s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 2/20 | val_loss:0.89155553 | f_score:0.04711088 | precision:0.03832121 | recall:0.99916946 | Time: 49.9496s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 3/20 | train_loss:0.86301625 | f_score:0.05532030 | precision:0.04523402 | recall:0.98762165 | Time: 173.0790s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 3/20 | val_loss:0.83541274 | f_score:0.04773537 | precision:0.03885347 | recall:0.99578422 | Time: 48.0856s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 4/20 | train_loss:0.80467238 | f_score:0.09877851 | precision:0.08544646 | recall:0.85028039 | Time: 175.6294s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 4/20 | val_loss:0.77576311 | f_score:0.11116892 | precision:0.09632639 | recall:0.78831187 | Time: 50.1759s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 5/20 | train_loss:0.77706587 | f_score:0.17809730 | precision:0.17749317 | recall:0.63188056 | Time: 180.7156s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 5/20 | val_loss:0.76839590 | f_score:0.15691597 | precision:0.14944256 | recall:0.67337087 | Time: 50.6252s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 6/20 | train_loss:0.76074459 | f_score:0.23819917 | precision:0.27681556 | recall:0.46597401 | Time: 174.2702s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 6/20 | val_loss:0.73711759 | f_score:0.30236464 | precision:0.35342583 | recall:0.34457325 | Time: 50.2567s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 7/20 | train_loss:0.74931045 | f_score:0.27573449 | precision:0.35779787 | recall:0.36095013 | Time: 172.9818s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 7/20 | val_loss:0.73730316 | f_score:0.27822631 | precision:0.31011814 | recall:0.40170978 | Time: 50.6345s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 8/20 | train_loss:0.74092924 | f_score:0.29544176 | precision:0.42206194 | recall:0.29869778 | Time: 178.9286s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 8/20 | val_loss:0.74976385 | f_score:0.22171881 | precision:0.23864213 | recall:0.51057749 | Time: 52.3672s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 9/20 | train_loss:0.73441012 | f_score:0.30638036 | precision:0.46818613 | recall:0.25880935 | Time: 175.7928s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 9/20 | val_loss:0.73045551 | f_score:0.32320682 | precision:0.44531033 | recall:0.27018614 | Time: 48.3969s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 10/20 | train_loss:0.73065850 | f_score:0.30863903 | precision:0.48349478 | recall:0.24740530 | Time: 174.8561s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 10/20 | val_loss:0.71660509 | f_score:0.33510784 | precision:0.52898976 | recall:0.22075632 | Time: 49.8313s\n",
      "\tPhase: train\n",
      "\t\t Epoch: 11/20 | train_loss:0.72621243 | f_score:0.31268079 | precision:0.50640938 | recall:0.22745685 | Time: 170.1599s\n",
      "\tPhase: val\n",
      "\t\t Epoch: 11/20 | val_loss:0.71474325 | f_score:0.34418966 | precision:0.52626294 | recall:0.22046351 | Time: 47.6810s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    for phase in ['train', 'val']:\n",
    "        start_time = time.time()\n",
    "        if phase == 'train':\n",
    "            NeuralNet.train()\n",
    "        else:\n",
    "            NeuralNet.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_f_score = 0.0\n",
    "        running_precision = 0.0\n",
    "        running_recall = 0.0\n",
    "\n",
    "        for images_batch, labels_batch in tqdm(dataloaders_dict[phase],disable = DISABLE_TQDM):\n",
    "            images_batch = images_batch.to(device, dtype=torch.float)\n",
    "            labels_batch = labels_batch.to(device, dtype=torch.float)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                pred_batch = NeuralNet(images_batch)\n",
    "                _, preds = torch.max(pred_batch.data, 1)\n",
    "                loss = loss_func(pred_batch,labels_batch)\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            labels_cpu = labels_batch.cpu().detach().numpy()\n",
    "            pred_cpu = pred_batch.cpu().detach().numpy()\n",
    "\n",
    "#             print(metrics.multilabel_confusion_matrix(labels_cpu, pred_cpu>0.5, samplewise = True))\n",
    "\n",
    "            temp_precision, temp_recall, temp_f_score, _ = precision_recall_fscore_support(\n",
    "                                                                labels_cpu, pred_cpu > 0.1, beta=0.5, average='samples')\n",
    "\n",
    "            running_loss += loss.item() * images_batch.size(0)\n",
    "            running_precision += (temp_precision * len(images_batch))\n",
    "            running_recall += (temp_recall * len(images_batch))\n",
    "            running_f_score += (temp_f_score * len(images_batch))\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_f_score = running_f_score / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_precision = running_precision / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_recall = running_recall / len(dataloaders_dict[phase].dataset)\n",
    "        \n",
    "        store(phase,epoch_precision,epoch_recall,epoch_f_score,epoch_loss)\n",
    "\n",
    "        if phase == 'val' and epoch_f_score < best_f_score:\n",
    "#             print(\"model val_loss Improved from {:.8f} to {:.8f}\".format(best_loss,epoch_loss))\n",
    "            best_f_score = epoch_f_score\n",
    "            best_precision = epoch_precision\n",
    "            best_recall = epoch_recall\n",
    "            best_loss = epoch_loss\n",
    "            best_model_wts = copy.deepcopy(NeuralNet.state_dict())\n",
    "            torch.save(NeuralNet.state_dict(), weights_path)\n",
    "\n",
    "        if phase == 'val':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        elapsed_time = time.time()-start_time\n",
    "        result(epoch, max_epochs,phase,epoch_loss,epoch_f_score,epoch_precision,epoch_recall,elapsed_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNet.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEFINE NETWORK\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "\n",
    "class _3d_cnn(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        \"\"\"\n",
    "        :param input_shape: input image shape, (h, w, c)\n",
    "        \"\"\"\n",
    "        super(_3d_cnn, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(input_channels,  16, (5, 1, 3), stride=(1, 1, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(16, 16, (1, 9, 3), stride=(1, 2, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool3d((2, 1, 1), stride=(2, 1, 1)),\n",
    "\n",
    "            nn.Conv3d(16, 32, kernel_size=(4, 1, 3), stride=(1, 1, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv3d(32, 32, kernel_size=(1, 8, 3), stride=(1, 2, 1)),\n",
    "            nn.PReLU(),\n",
    "            nn.MaxPool3d((2, 1, 1), stride=(2, 1, 1)),\n",
    "            \n",
    "            nn.AvgPool3d(2)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        input_shape = (1,) + input_shape\n",
    "        x = Variable(torch.rand(input_shape), requires_grad=False)\n",
    "        x = self.features(x)\n",
    "        x = Flatten()(x)\n",
    "        self.n = x.size()[1]\n",
    "        print(num_features)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(self.n, num_features)\n",
    "        self.fc2 = nn.Linear(num_features, output_dim)\n",
    "        self.bn = nn.BatchNorm1d(self.n)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = Flatten()(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "newmodel = _3d_cnn(input_shape, output_dim)\n",
    "newmodel.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_3d_cnn(\n",
       "  (features): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(5, 1, 3), stride=(1, 1, 1))\n",
       "    (1): PReLU(num_parameters=1)\n",
       "    (2): Conv3d(16, 16, kernel_size=(1, 9, 3), stride=(1, 2, 1))\n",
       "    (3): PReLU(num_parameters=1)\n",
       "    (4): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv3d(16, 32, kernel_size=(4, 1, 3), stride=(1, 1, 1))\n",
       "    (6): PReLU(num_parameters=1)\n",
       "    (7): Conv3d(32, 32, kernel_size=(1, 8, 3), stride=(1, 2, 1))\n",
       "    (8): PReLU(num_parameters=1)\n",
       "    (9): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=932, bias=True)\n",
       "  (bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_tensor(pdb_id):\n",
    "    X = np.empty((max(1,len(weights)),\n",
    "                      v_size,\n",
    "                      v_size,\n",
    "                      v_size))\n",
    "\n",
    "    coords = load_coords(pdb_id, p, precomputed_path)\n",
    "    coords = coords_center_to_zero(coords)\n",
    "    coords = adjust_size(coords, v_size=v_size, max_radius=max_radius)\n",
    "\n",
    "    # Get weights\n",
    "    local_weights = []\n",
    "    for weight in weights:\n",
    "        local_weight = load_weights(pdb_id, weight, p,\n",
    "                                    scaling_weights, precomputed_path) # Compute extended weights\n",
    "        local_weights += [local_weight] # Store\n",
    "\n",
    "    # PCA\n",
    "    coords = PCA(n_components=3).fit_transform(coords)\n",
    "\n",
    "    # Do flip\n",
    "    coords_temp = flip_around_axis(coords, axis=flips)\n",
    "\n",
    "    if len(weights) == 0:\n",
    "        # Convert to volume and store\n",
    "        X[0, :, :, :] = coords_to_volume(coords_temp, v_size,\n",
    "                                            noise_treatment=noise_treatment)\n",
    "\n",
    "    else:\n",
    "        # Compute to weights of volume and store\n",
    "        for k in range(max(1,len(weights))):\n",
    "            X[k, :, :, :] = weights_to_volume(coords_temp, local_weights[k],\n",
    "                                                 v_size, noise_treatment=noise_treatment)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "accession = []\n",
    "temp = list(acc_pdb)\n",
    "newmodel.to(device)\n",
    "\n",
    "for acc in temp[1:]:\n",
    "    pdb = acc_pdb[acc]\n",
    "    img_numpy = get_image_tensor(pdb)\n",
    "    img_tensor = torch.tensor(img_numpy)\n",
    "    img_tensor = img_tensor.unsqueeze(0)\n",
    "    img_tensor = img_tensor.to(device, dtype=torch.float)\n",
    "    pred = newmodel(img_tensor)\n",
    "    temp = pred.cpu().detach().numpy()\n",
    "    features.append(temp)\n",
    "    accession.append(acc)\n",
    "res_df = pd.DataFrame({'accession': acc,'features':features})\n",
    "\n",
    "res_df.to_pickle(features_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    }
   ],
   "source": [
    "print(len(features[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
